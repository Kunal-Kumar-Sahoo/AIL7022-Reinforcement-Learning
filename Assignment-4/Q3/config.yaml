A2C:
  InvertedPendulum-v5:
    n_envs: 8
    total_timesteps: 50000
    policy_type: "MlpPolicy"
    learning_rate: 0.0007
    n_steps: 5
    gamma: 0.99
    gae_lambda: 1.0
    ent_coef: 0.0
    vf_coef: 0.5
    max_grad_norm: 0.5
    policy_kwargs: "dict(net_arch=dict(pi=[64, 64], vf=[64, 64]))"

  Hopper-v5:
    n_envs: 1
    total_timesteps: 1000000
    policy_type: "MlpPolicy"
    learning_rate: 0.0007
    n_steps: 512
    gamma: 0.99
    gae_lambda: 1.0
    ent_coef: 0.0
    vf_coef: 0.5
    max_grad_norm: 0.5
    use_sde: True
    policy_kwargs: "dict(activation_fn=torch.nn.SiLU, net_arch=dict(pi=[512, 512], vf=[512, 512]))"

  HalfCheetah-v5:
    n_envs: 1
    total_timesteps: 2000000
    policy_type: "MlpPolicy"
    learning_rate: 0.0007
    n_steps: 2048
    gamma: 0.99
    gae_lambda: 1.0
    ent_coef: 0.0
    vf_coef: 0.5
    max_grad_norm: 0.5
    use_sde: True
    policy_kwargs: "dict(activation_fn=torch.nn.SiLU, net_arch=dict(pi=[1024, 1024], vf=[1024, 1024]))"

PPO:
  InvertedPendulum-v5:
    n_envs: 8
    total_timesteps: 50000
    policy_type: "MlpPolicy"
    learning_rate: 0.0003
    n_steps: 2048
    batch_size: 64
    n_epochs: 10
    gamma: 0.99
    gae_lambda: 0.95
    clip_range: 0.2
    ent_coef: 0.0
    policy_kwargs: "dict(net_arch=dict(pi=[64, 64], vf=[64, 64]))"

  Hopper-v5:
    n_envs: 1
    total_timesteps: 1000000
    policy_type: "MlpPolicy"
    learning_rate: 0.0003
    n_steps: 512
    batch_size: 64
    n_epochs: 10
    gamma: 0.99
    gae_lambda: 0.95
    clip_range: 0.2
    ent_coef: 0.0
    use_sde: True
    policy_kwargs: "dict(activation_fn=torch.nn.SiLU, net_arch=dict(pi=[512, 512], vf=[512, 512]))"

  HalfCheetah-v5:
    n_envs: 1
    total_timesteps: 2000000
    policy_type: "MlpPolicy"
    learning_rate: 0.0003
    n_steps: 2048
    batch_size: 64
    n_epochs: 10
    gamma: 0.99
    gae_lambda: 0.95
    clip_range: 0.2
    ent_coef: 0.0
    use_sde: True
    policy_kwargs: "dict(activation_fn=torch.nn.SiLU, net_arch=dict(pi=[1024, 1024], vf=[1024, 1024]))"